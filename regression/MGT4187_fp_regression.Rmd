---
title: "MGT4187_Final Project (Regression)"
author: "Zhu Yiran"
date: "4/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd("/Users/sunhangzi/Desktop/MGT4187/video")
hot_video=read.csv("hot_video.csv")
# The mean of each area's view, duration, danmaku, reply, favoriate, coin, share, and like
unique_area=unique(hot_video$area_eng)
sta=data.frame()
i=1
for (area in unique_area){
  hot_video_area=hot_video[hot_video$area_eng==area,c(9,6,8,10:13)]
  sta[i,1:7]=apply(hot_video_area,2,mean)
  i=i+1
}
names(sta)=c("reply","view","danmaku","favorite","coin","share","like")
row.names(sta)=unique_area
sta
# The mean ranking of each area's view, duration, danmaku, reply, favoriate, coin, share, and like
sta_rank=data.frame()
for (i in 1:7){
  sta_rank[1:16,i]=rank(-sta[1:16,i])
}
names(sta_rank)=c("reply","view","danmaku","favorite","coin","share","like")
row.names(sta_rank)=unique_area
sta_rank
# The number of danmaku, reply, favoriate, coin, share, and like per view
sta_per_view=matrix(ncol=6,nrow=16)
sta_per_view[,1]=sta[,5]/sta[,2]  # coin per view
sta_per_view[,2]=sta[,1]/sta[,2]  # reply per view
sta_per_view[,3]=sta[,4]/sta[,2]  # favoriate per view
sta_per_view[,4]=sta[,3]/sta[,2] # danmaku per view
sta_per_view[,5]=sta[,6]/sta[,2]  # share per view
sta_per_view[,6]=sta[,7]/sta[,2]  # like per view
sta_per_view_rank=data.frame()
for (i in 1:6){
  sta_per_view_rank[1:16,i]=rank(-sta_per_view[1:16,i])
}
names(sta_per_view_rank)=c("coin","reply","favorite","danmaku","share","like")
row.names(sta_per_view_rank)=unique_area
sta_per_view_rank
```

```{r}
sta_rank
sta_rank[order(sta_rank$reply),]
sta_per_view_rank
sta_per_view_rank[order(sta_per_view_rank$coin),]
```

```{r}
library(ggplot2)
hot_video_500=read.csv("hot_video_top500.csv")
hot_video_500$area_eng=NA
hot_video_500$area_eng[1:100]='Household' # 家居房产
hot_video_500$area_eng[101:200]='Daily' # 日常
hot_video_500$area_eng[201:300]='Drawing' # 绘画
hot_video_500$area_eng[301:400]='Handcraft' # 手工
hot_video_500$area_eng[401:500]='Funny' # 搞笑
hot_video_500$coin_view=hot_video_500$coin/hot_video_500$view
hot_video_500$danmaku_view=hot_video_500$danmaku/hot_video_500$view
hot_video_500$reply_view=hot_video_500$reply/hot_video_500$view
hot_video_500$favorite_view=hot_video_500$favorite/hot_video_500$view
hot_video_500$share_view=hot_video_500$share/hot_video_500$view
hot_video_500$like_view=hot_video_500$like/hot_video_500$view

# density plot
ggplot(hot_video_500,aes(view,fill=area_eng, color=area_eng)) + xlab("The number of viewers") + geom_density(alpha = 0.6) + geom_rug() + theme_bw()
ggplot(hot_video_500,aes(coin,fill=area_eng, color=area_eng)) + xlab("The number of coins") + geom_density(alpha = 0.6) + geom_rug() + theme_bw()
ggplot(hot_video_500,aes(coin_view,fill=area_eng, color=area_eng)) + xlab("The number of coins per viewer") + geom_density(alpha = 0.6) + geom_rug() + theme_bw()
# time series plot
#ggplot(hot_video_500,aes(x=as.Date(time), y=view)) + geom_line() + xlab("")
#ggplot(hot_video_500,aes(x=as.Date(time), y=coin_view)) + geom_line() + xlab("")
# mean
unique_area=unique(hot_video_500$area_eng)
sta=data.frame()
i=1
for (area in unique_area){
  hot_video_area=hot_video_500[hot_video_500$area_eng==area,c(7,11,21)]
  sta[i,1:3]=apply(hot_video_area,2,mean)
  i=i+1
}
names(sta)=c("view","coin","coin per view")
row.names(sta)=unique_area
sta
# mean ranking
sta_rank=data.frame()
for (i in 1:3){
  sta_rank[1:5,i]=rank(sta[1:5,i])
}
names(sta_rank)=c("duration","coin","coin per view")
row.names(sta_rank)=unique_area
sta_rank
```

```{r}
library(car)
# descriptive data
summary=data.frame()
for (i in 7:13){
  summary[i-6,1]=min(hot_video_500[,i])
  summary[i-6,2]=mean(hot_video_500[,i])
  summary[i-6,3]=median(hot_video_500[,i])
  summary[i-6,4]=max(hot_video_500[,i])
  summary[i-6,5]=sd(hot_video_500[,i])
}
names(summary)=c("min","mean","median","max","standard deviation")
row.names(summary)=c("view","danmaku","reply","favoriate","coin","share","like")
summary
# write.table(summary,sep=" ",file="regression1_summary.csv",row.names =TRUE,col.names=TRUE,quote =TRUE)
# linear regression
lm_estimation=lm(coin ~ view+danmaku+reply+favorite+share+like, data = hot_video_500)
summary(lm_estimation)
vif(lm_estimation)
# linear regression (log)

#lm_estimation=lm(log(coin) ~ log(view)+log(danmaku+1)+log(reply+1)+log(favorite)+log(share+1), data = hot_video_500_new)
#summary(lm_estimation)
#vif(lm_estimation)
```

```{r}
hot_video_500_factor=hot_video_500
# The number of tags
for (i in 1:nrow(hot_video_500)){
  num=0
  for (j in 1:nchar(as.character(hot_video_500[i,2]))){
    if (substring(as.character(hot_video_500[i,2]),j,j)==','){
      num=num+1 # the number of comma
    }
  }
  hot_video_500_factor$tag_num[i]=num+1 
}

# The title of the video
# The length of the title
hot_video_500_factor$title_len=nchar(as.character(hot_video_500_factor$title)) 
# Whether the title includes a tag or not
hot_video_500_factor$title_tag=0
for (i in 1:nrow(hot_video_500_factor)){
  for (j in 1:nchar(as.character(hot_video_500_factor[i,5]))){
    if ((substring(as.character(hot_video_500[i,5]),j,j)=='【') |  (substring(as.character(hot_video_500[i,5]),j,j)=='】')) {
      hot_video_500_factor$title_tag[i]=1
    }
  }
}
# Whether the title includes an emotional symbol or not
hot_video_500_factor$title_symbol=0
for (i in 1:nrow(hot_video_500_factor)){
  for (j in 1:nchar(as.character(hot_video_500_factor[i,5]))){
    if ((substring(as.character(hot_video_500[i,5]),j,j)=='！')|(substring(as.character(hot_video_500[i,5]),j,j)=='？')|(substring(as.character(hot_video_500[i,5]),j,j)=='。')|(substring(as.character(hot_video_500[i,5]),j,j)=='.')|(substring(as.character(hot_video_500[i,5]),j,j)=='～')) {
      hot_video_500_factor$title_symbol[i]=1
    }
  }
}
# Date
for (i in 1:nrow(hot_video_500_factor)){
  hot_video_500_factor$month[i]=substring(as.character(hot_video_500_factor[i,4]),1,7)
}
# Regression
lm_estimation_factor1=lm(view ~ duration+tag_num+title_len+title_symbol+title_tag+author_follower+I(landscape)+I(area)+I(month)+I(landscape)*I(area), data =hot_video_500_factor)
summary(lm_estimation_factor1)
vif(lm_estimation_factor1) # There is no problem of multicollinearity
```

```{r}
# lm_estimation_factor1=lm(view ~ duration+tag_num+title_len+title_symbol+title_tag+author_follower+I(landscape)+I(area)+I(month)+I(landscape)*I(area), data =hot_video_500_factor)
summary(hot_video_500_factor$duration)
sd(hot_video_500_factor$duration)
summary(hot_video_500_factor$tag_num)
sd(hot_video_500_factor$tag_num)
summary(hot_video_500_factor$title_len)
sd(hot_video_500_factor$title_len)
summary(hot_video_500_factor$author_follower)
sd(hot_video_500_factor$author_follower)
sum(hot_video_500_factor$title_symbol)
sum(hot_video_500_factor$title_tag)
nrow(hot_video_500_factor[hot_video_500_factor$month=='2022-03',])
nrow(hot_video_500_factor[hot_video_500_factor$landscape=='Y',])
```

```{r}
library(car)
lm_estimation_factor2=lm(coin_view ~ duration+tag_num+title_len+title_symbol+title_tag+author_follower+I(landscape)+I(area)+I(month)+I(landscape)*I(area), data =hot_video_500_factor)
summary(lm_estimation_factor2)
vif(lm_estimation_factor2) # There is no problem of multicollinearity
```

```{r}
# regression 1
# Ridge
library(glmnet)
x=as.matrix(log(hot_video_500_new[,c(7:10,12)]+1))
y=log(hot_video_500_new[,11]+1)
cv.out=cv.glmnet(x,y,alpha=0) #use cv to choose the best lambda
bestlam=cv.out$lambda.min
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:6,]
# Lasso
cv.out=cv.glmnet(x,y,alpha=1) 
bestlam=cv.out$lambda.min
out=glmnet(x,y,alpha=1)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:6,]
lasso.coef[lasso.coef!=0]
```
